// Copyright (c) 2025 WSO2 LLC (http://www.wso2.com).
//
// WSO2 LLC. licenses this file to you under the Apache License,
// Version 2.0 (the "License"); you may not use this file except
// in compliance with the License.
// You may obtain a copy of the License at
//
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing,
// software distributed under the License is distributed on an
// "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
// KIND, either express or implied.  See the License for the
// specific language governing permissions and limitations
// under the License.

import ballerina/ai;
import ballerina/http;

const DEFAULT_ANTHROPIC_SERVICE_URL = "https://api.anthropic.com/v1";
const DEFAULT_MAX_TOKEN_COUNT = 512;
const DEFAULT_TEMPERATURE = 0.7d;
const ANTHROPIC_API_VERSION = "2023-06-01";

# Provider is a client class that provides an interface for interacting with Anthropic Large Language Models.
public isolated client class Provider {
    *ai:ModelProvider;
    private final http:Client AnthropicClient;
    private final string apiKey;
    private final string modelType;
    private final int maxTokens;

    # Initializes the Anthropic model with the given connection configuration and model configuration.
    #
    # + apiKey - The Anthropic API key
    # + modelType - The Anthropic model name
    # + apiVersion - The Anthropic API version (e.g., "2023-06-01")  
    # + serviceUrl - The base URL of Anthropic API endpoint
    # + maxTokens - The upper limit for the number of tokens in the response generated by the model
    # + temperature - The temperature for controlling randomness in the model's output  
    # + connectionConfig - Additional HTTP connection configuration
    # + return - `nil` on successful initialization; otherwise, returns an `ai:Error`
    public isolated function init(@display {label: "API Key"} string apiKey,
            @display {label: "Model Type"} ANTHROPIC_MODEL_NAMES modelType,
            @display {label: "Service URL"} string serviceUrl = DEFAULT_ANTHROPIC_SERVICE_URL,
            @display {label: "Maximum Tokens"} int maxTokens = DEFAULT_MAX_TOKEN_COUNT,
            @display {label: "Temperature"} decimal temperature = DEFAULT_TEMPERATURE,
            @display {label: "Connection Configuration"} *ConnectionConfig connectionConfig) returns ai:Error? {

        // Convert ConnectionConfig to http:ClientConfiguration
        http:ClientConfiguration anthropicConfig = {
            httpVersion: connectionConfig.httpVersion,
            http1Settings: connectionConfig.http1Settings ?: {},
            http2Settings: connectionConfig?.http2Settings ?: {},
            timeout: connectionConfig.timeout,
            forwarded: connectionConfig.forwarded,
            poolConfig: connectionConfig?.poolConfig,
            cache: connectionConfig?.cache ?: {},
            compression: connectionConfig.compression,
            circuitBreaker: connectionConfig?.circuitBreaker,
            retryConfig: connectionConfig?.retryConfig,
            responseLimits: connectionConfig?.responseLimits ?: {},
            secureSocket: connectionConfig?.secureSocket,
            proxy: connectionConfig?.proxy,
            validation: connectionConfig.validation
        };

        http:Client|error httpClient = new http:Client(serviceUrl, anthropicConfig);
        if httpClient is error {
            return error ai:Error("Failed to initialize Anthropic Model", httpClient);
        }

        self.AnthropicClient = httpClient;
        self.apiKey = apiKey;
        self.modelType = modelType;
        self.maxTokens = maxTokens;
    }

    # Converts standard ai:ChatMessage array to Anthropic's message format
    #
    # + messages - List of chat messages 
    # + return - return value description
    private isolated function mapToAnthropicMessages(ai:ChatMessage[] messages) returns AnthropicMessage[] {
        AnthropicMessage[] anthropicMessages = [];

        foreach ai:ChatMessage message in messages {
            if message is ai:ChatUserMessage {
                anthropicMessages.push({
                    role: ai:USER,
                    content: message.content
                });
            } else if message is ai:ChatSystemMessage {
                // Add a user message containing the system prompt
                anthropicMessages.push({
                    role: ai:USER,
                    content: string `<system>${message.content}</system>\n\n`
                });
            } else if message is ai:ChatAssistantMessage && message.content is string {
                anthropicMessages.push({
                    role: ai:ASSISTANT,
                    content: message.content ?: ""
                });
            } else if message is ai:ChatFunctionMessage && message.content is string {
                // Include function results as user messages with special formatting
                anthropicMessages.push({
                    role: ai:USER,
                    content: string `<function_results>\nFunction: ${message.name}\n`
                        + string `Output: ${message.content ?: ""}\n</function_results>`
                });
            }
        }
        return anthropicMessages;
    }

    # Maps ai:ChatCompletionFunctions to Anthropic's tool format
    #
    # + tools - Array of tool definitions
    # + return - Array of Anthropic tool definitions
    private isolated function mapToAnthropicTools(ai:ChatCompletionFunctions[] tools) returns AnthropicTool[] {
        AnthropicTool[] anthropicTools = [];

        foreach ai:ChatCompletionFunctions tool in tools {
            ai:JsonInputSchema schema = tool.parameters ?: {'type: "object", properties: {}};

            // Create Anthropic tool with input_schema instead of parameters
            AnthropicTool AnthropicTool = {
                name: tool.name,
                description: tool.description,
                input_schema: schema
            };

            anthropicTools.push(AnthropicTool);
        }

        return anthropicTools;
    }

    # Uses Anthropic API to generate a response
    # + messages - List of chat messages 
    # + tools - Tool definitions to be used for the tool call
    # + stop - Stop sequence to stop the completion (not used in this implementation)
    # + return - Chat response or an error in case of failures
    isolated remote function chat(ai:ChatMessage[] messages, ai:ChatCompletionFunctions[] tools = [], string? stop = ())
        returns ai:ChatAssistantMessage|ai:LlmError {

        // Map messages to Anthropic format
        AnthropicMessage[] anthropicMessages = self.mapToAnthropicMessages(messages);

        // Prepare request payload
        map<json> requestPayload = {
            "model": self.modelType,
            "max_tokens": self.maxTokens,
            "messages": anthropicMessages
        };

        if stop is string {
            requestPayload["stop_sequences"] = [stop];
        }

        // If tools are provided, add them to the request
        if tools.length() > 0 {
            requestPayload["tools"] = self.mapToAnthropicTools(tools);
        }

        // Send request to Anthropic API with proper headers
        map<string> headers = {
            "x-api-key": self.apiKey,
            "anthropic-version": ANTHROPIC_API_VERSION,
            "content-type": "application/json"
        };

        AnthropicApiResponse|error anthropicResponse = self.AnthropicClient->/messages.post(requestPayload, headers);
        if anthropicResponse is error {
            return error ai:LlmInvalidResponseError("Unexpected response format from Anthropic API", anthropicResponse);
        }

        string? content = ();
        ai:FunctionCall[] toolCalls = [];
        foreach ContentBlock block in anthropicResponse.content {
            string blockType = block.'type;
            if blockType == "tool_use" {
                toolCalls.push(check self.mapContentToFunctionCall(block));
            } else if blockType == "text" {
                content = block.text;
            }
        }
        return {role: ai:ASSISTANT, toolCalls: toolCalls == [] ? () : toolCalls, content};
    }

    private isolated function mapContentToFunctionCall(ContentBlock block) returns ai:FunctionCall|ai:LlmError {
        string? blockName = block.name;
        if blockName is () {
            return error ai:LlmError("Invalid or malformed name received in function call response.");
        }
        json inputJson = block?.input;
        map<json>?|error arguments = inputJson.cloneWithType();
        if arguments is error {
            return error ai:LlmError("Invalid or malformed arguments received in function call response.", arguments);
        }
        return {name: blockName, arguments};
    }
}
